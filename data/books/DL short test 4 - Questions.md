
## Short Test 4: Self-Supervised Learning, Generative Model, **7Min**

Single-choice problem: All questions in this problem can be answered *independently*. Only one answer per question is correct. Please *circle* this answer on the problem sheet.

1. Which statement is *wrong* about an autoencoder?

A: It requires labeled input data. B: It consists of an encoder-decoder structure.

C: It encodes the input samples into a latent space.

D: The goal is to reconstruct the input by a lower dimensional latent space.

2. Which statement is *wrong* about self-supervised learning?

A: It is a branch of unsupervised learning. B: It learns without a loss function for supervision. C: It is often used for self-supervised representation learning. D: It employs supervised learning techniques with an unlabeled dataset.

3. Which task is not a suitable pretext task for self-supervised representation learning of images?

A: Self-reconstruction by an autoencoder. B: Flip of an image. C: Image classification. D: Image colorization.

4. Which statement is *wrong* about contrastive learning?

A: It is a kind of self-supervised representation learning.

B: It learns to contrast between two classes in a binary classification task.

C: It contrasts between positive and negative views generated from unlabeled images.

D: It employs rich data augmentations.

5. Which statement is *wrong* about a discriminative model?

A: It learns the joint distribution p(x, y). B: It is able of classification.

C: It is able of regression. D: It focuses on the decision boundaries.

6. Which statement is correct about a generative model?

A: It is not able of classification.

B: It is not able of regression.

C: Training a generative model is more difficult than a discriminative model.

D: It focuses on the decision boundaries.

7. Which neural network is a generative model?

A: CNN B: RNN C: Autoencoder D: GAN E: none of them